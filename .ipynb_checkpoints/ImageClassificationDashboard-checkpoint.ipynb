{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9366cfaa-0a6d-4c9a-bc2f-291c149b0653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maddy\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maddy\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.0.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Maddy\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.0.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2024-08-31 15:25:21.286 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Maddy\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "from PIL import Image\n",
    "import pywt  # Import PyWavelets for wavelet transformation\n",
    "\n",
    "# Load the trained model and class dictionary\n",
    "model = joblib.load('./saved_model.pkl')\n",
    "with open(\"./class_dictionary.json\", \"r\") as f:\n",
    "    class_dict = json.load(f)\n",
    "\n",
    "# Load Haar cascades for face and eye detection\n",
    "face_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "# Define the function to detect face and eyes and crop the image\n",
    "def get_cropped_image_if_2_eyes(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        roi_color = image[y:y + h, x:x + w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        if len(eyes) >= 2:\n",
    "            return roi_color\n",
    "    return None\n",
    "\n",
    "# Define the function to extract features using Wavelet Transform\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    imArray = np.float32(imArray)\n",
    "    imArray /= 255\n",
    "    coeffs = pywt.wavedec2(imArray, mode, level=level)\n",
    "    coeffs_H = list(coeffs)\n",
    "    coeffs_H[0] *= 0\n",
    "    imArray_H = pywt.waverec2(coeffs_H, mode)\n",
    "    imArray_H *= 255\n",
    "    imArray_H = np.uint8(imArray_H)\n",
    "    return imArray_H\n",
    "\n",
    "# Streamlit app interface\n",
    "st.title(\"Character Image Classification\")\n",
    "st.write(\"Upload an image to classify the character.\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    image = Image.open(uploaded_file)\n",
    "    image_np = np.array(image)\n",
    "    st.image(image_np, caption='Uploaded Image', use_column_width=True)\n",
    "    \n",
    "    cropped_image = get_cropped_image_if_2_eyes(image_np)\n",
    "    \n",
    "    if cropped_image is not None:\n",
    "        scalled_raw_img = cv2.resize(cropped_image, (32, 32))\n",
    "        img_har = w2d(cropped_image, 'db1', 5)\n",
    "        scalled_img_har = cv2.resize(img_har, (32, 32))\n",
    "        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3, 1), scalled_img_har.reshape(32*32, 1)))\n",
    "        combined_img = combined_img.reshape(1, 4096).astype(float)\n",
    "        \n",
    "        prediction = model.predict(combined_img)\n",
    "        predicted_class = list(class_dict.keys())[list(class_dict.values()).index(prediction[0])]\n",
    "        \n",
    "        st.write(f\"Predicted Character: {predicted_class}\")\n",
    "    else:\n",
    "        st.write(\"Unable to detect face with 2 eyes in the image.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
